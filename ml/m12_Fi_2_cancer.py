from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier, XGBRegressor
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import warnings

warnings.filterwarnings('ignore')

# 1. 데이터

dataset = load_breast_cancer()
# x_train, x_test, y_train, y_test = train_test_split(dataset.data, dataset.target,
#                     train_size=0.8, random_state=66
# )

# # 2. 모델

# # model = DecisionTreeClassifier()
# # 기존
# # acc : 0.9298245614035088
# # [0.         0.05940707 0.         0.         0.         0.
# #  0.         0.01967507 0.         0.00468454 0.01233852 0.
# #  0.         0.         0.01405362 0.02248579 0.         0.00433754
# #  0.         0.         0.         0.01612033 0.         0.71474329
# #  0.00468454 0.         0.00461856 0.11660508 0.         0.00624605]

# # model = RandomForestClassifier()
# # 기존
# # acc : 0.956140350877193
# # [0.02219081 0.01755088 0.04916617 0.04137464 0.00657347 0.01317642
# #  0.05128476 0.06427036 0.00433481 0.00370756 0.01332462 0.00482273
# #  0.00962975 0.02958542 0.00347491 0.00427061 0.00749795 0.00417713
# #  0.00506002 0.00511553 0.15684721 0.01564279 0.12547708 0.117608
# #  0.00951396 0.0157771  0.02676024 0.15444403 0.0106431  0.00669794]

# # model = GradientBoostingClassifier()
# # 기존
# # acc : 0.956140350877193
# # [2.01920496e-05 3.76382499e-02 1.87739266e-03 2.21461971e-03
# #  2.17241055e-03 3.32716293e-06 8.38334256e-04 1.17497982e-01
# #  2.86255888e-03 4.76803745e-03 4.06182068e-03 5.47327676e-06
# #  4.86620270e-04 1.80691941e-02 6.74183424e-04 5.44334617e-05
# #  5.92367062e-03 1.41442060e-03 1.71978108e-05 4.20883720e-04
# #  3.27551281e-01 4.06432972e-02 4.65358989e-02 2.61503707e-01
# #  4.36466979e-03 2.86703227e-04 1.40731851e-02 1.03643122e-01
# #  2.10156853e-05 3.56117501e-04]

# # model =  XGBClassifier()
# # 기존
# # acc : 0.9736842105263158
# # [0.01420499 0.03333857 0.         0.02365488 0.00513449 0.06629944
# #  0.0054994  0.09745205 0.00340272 0.00369179 0.00769184 0.00281184
# #  0.01171023 0.0136856  0.00430626 0.0058475  0.00037145 0.00326043
# #  0.00639412 0.0050556  0.01813928 0.02285903 0.22248562 0.28493083
# #  0.00233393 0.         0.00903706 0.11586285 0.00278498 0.00775311]

# # 3. 훈련

# model.fit(x_train, y_train)

# # 4. 평가, 예측

# acc = model.score(x_test, y_test)

# # 5. 시각화

# def plot_feature_importances_dataset(model):
#     n_features = dataset.data.shape[1]
#     plt.barh(np.arange(n_features), model.feature_importances_,
#                 align='center')
#     plt.yticks(np.arange(n_features), dataset.feature_names)
#     plt.xlabel("Feature Importancs")
#     plt.ylabel("Features")
#     plt.ylim(-1, n_features)

# plot_feature_importances_dataset(model)
# plt.show()

# print("acc :", acc)

# print(model.feature_importances_)

###################################################################

# 중요도 하위 20%의 컬럼 제거 후, 모델 비교

dataset_data = pd.DataFrame(dataset.data)

dataset_data = dataset_data.drop([3,25,29,5,6,0], axis=1)
dataset_data = np.array(dataset_data)

x_train, x_test, y_train, y_test = train_test_split(dataset_data, dataset.target,
                    train_size=0.8, random_state=66
)

# 2. 모델

# model = DecisionTreeClassifier()
# 기존
# acc : 0.9298245614035088
# [0.         0.05940707 0.         0.         0.         0.
#  0.         0.01967507 0.         0.00468454 0.01233852 0.
#  0.         0.         0.01405362 0.02248579 0.         0.00433754
#  0.         0.         0.         0.01612033 0.         0.71474329
#  0.00468454 0.         0.00461856 0.11660508 0.         0.00624605]

# 제거
# acc : 0.9385964912280702
# [0.05940707 0.         0.00702681 0.01967507 0.         0.
#  0.         0.         0.         0.01233852 0.         0.02248579
#  0.01405362 0.00433754 0.         0.         0.         0.02548941
#  0.         0.72098934 0.         0.00461856 0.10957827 0.        ]

# model = RandomForestClassifier()
# 기존
# acc : 0.956140350877193
# [0.02219081 0.01755088 0.04916617 0.04137464 0.00657347 0.01317642
#  0.05128476 0.06427036 0.00433481 0.00370756 0.01332462 0.00482273
#  0.00962975 0.02958542 0.00347491 0.00427061 0.00749795 0.00417713
#  0.00506002 0.00511553 0.15684721 0.01564279 0.12547708 0.117608
#  0.00951396 0.0157771  0.02676024 0.15444403 0.0106431  0.00669794]

# 제거
# acc : 0.956140350877193
# [0.01494838 0.04789909 0.00743002 0.08216604 0.00522613 0.00518109
#  0.01744654 0.00461011 0.02525998 0.07397578 0.00580931 0.00499011
#  0.0103155  0.00745051 0.00487837 0.00468216 0.12285987 0.0260701
#  0.17664729 0.13799145 0.01041367 0.05903906 0.1303058  0.01440365]

# model = GradientBoostingClassifier()
# 기존
# acc : 0.956140350877193
# [2.01920496e-05 3.76382499e-02 1.87739266e-03 2.21461971e-03
#  2.17241055e-03 3.32716293e-06 8.38334256e-04 1.17497982e-01
#  2.86255888e-03 4.76803745e-03 4.06182068e-03 5.47327676e-06
#  4.86620270e-04 1.80691941e-02 6.74183424e-04 5.44334617e-05
#  5.92367062e-03 1.41442060e-03 1.71978108e-05 4.20883720e-04
#  3.27551281e-01 4.06432972e-02 4.65358989e-02 2.61503707e-01
#  4.36466979e-03 2.86703227e-04 1.40731851e-02 1.03643122e-01
#  2.10156853e-05 3.56117501e-04]

# 제거
# acc : 0.956140350877193
# [3.57386126e-02 1.88467543e-03 9.56269531e-04 1.30353923e-01
#  2.90189601e-03 2.50901414e-04 3.94950809e-03 2.29524816e-04
#  2.36155853e-03 1.77926537e-02 5.22991595e-04 4.02259285e-03
#  2.00357240e-03 4.99810895e-04 1.33078705e-05 5.64890101e-03
#  3.11009875e-01 4.30944427e-02 3.70013030e-02 2.75005773e-01
#  5.82210937e-03 1.37625967e-02 1.05158098e-01 1.51024317e-05]

# model =  XGBClassifier()
# 기존
# acc : 0.9736842105263158
# [0.01420499 0.03333857 0.         0.02365488 0.00513449 0.06629944
#  0.0054994  0.09745205 0.00340272 0.00369179 0.00769184 0.00281184
#  0.01171023 0.0136856  0.00430626 0.0058475  0.00037145 0.00326043
#  0.00639412 0.0050556  0.01813928 0.02285903 0.22248562 0.28493083
#  0.00233393 0.         0.00903706 0.11586285 0.00278498 0.00775311]

# 제거
# acc : 0.9736842105263158
# [0.03091158 0.00417674 0.00631439 0.08158708 0.00186584 0.00337825
#  0.01327293 0.00114263 0.01973083 0.01247483 0.00288842 0.00354216
#  0.00530519 0.00289701 0.00425689 0.00557047 0.00548398 0.01744858
#  0.45008075 0.23510209 0.00153415 0.00944848 0.07953392 0.00205283]

# 3. 훈련

model.fit(x_train, y_train)

# 4. 평가, 예측

acc = model.score(x_test, y_test)

print("acc :", acc)
print(model.feature_importances_)

# 모델별로 importance값이 다른경우가 존재하기 때문에 (많이는아님) 어떠한 모델을 사용하는지에따라
# 소거해줄 coulmns을 결정해줘야한다.

# importance값이 애초에 0일경우 소거해주어도 결과값에 변화를 주진못한다.
# 하지만 속도에는 영향을 미칠것이다.